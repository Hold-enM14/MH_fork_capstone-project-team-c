---
title: "EDA"
output: html_document
date: "2025-11-14"
---

libraries
```{r}
library(here)
library(dplyr)
library(lubridate)
library(readr)
library(tibble)
library(knitr)
```

Importing data
```{r}
weather = read.csv(here("data","raw-data","weather-data.csv"))
airquality = read.csv(here("data","raw-data","air-quality-data.csv"))
boston = read.csv(here("data","raw-data","boston-marathon-data.csv"))
chicago = read.csv(here("data","raw-data","chicago-marathon-data.csv"))
nyc = read.csv(here("data","raw-data","nyc-marathon-data.csv"))
berlin = read.csv(here("data","raw-data","berlin-marathon-data.csv"))
```

Taking a look at the datasets
```{r}
str(boston)
str(berlin)
str(nyc)
str(chicago)
str(weather)
str(airquality)
```

Standardize all the marathon datasets
```{r}
boston_clean <- boston %>%
  transmute(
    year = year,
    marathon = "Boston",
    gender = gender,
    chip_time = official_time
  )

berlin_clean <- berlin %>%
  transmute(
    year = YEAR,
    marathon = "Berlin",
    gender = GENDER,
    chip_time = TIME
  )

nyc_clean <- nyc %>%
  transmute(
    year = Year,
    marathon = "NYC",
    gender = Gender,
    chip_time = Finish.Time
  )

chicago_clean <- chicago %>%
  transmute(
    year = Year,
    marathon = "Chicago",
    gender = Gender,
    chip_time = Finish.Time
  )
```

Standardize weather data
```{r}
weather_clean <- weather %>%
  transmute(
    year = Year,
    marathon = Marathon,
    high_temp = High.Temp,
    low_temp = Low.Temp,
    avg_temp = Day.Average.Temp,
    precipitation = Precipitation,
    dew_point = Average.Dew.Point,
    wind_speed = Max.Wind.Speed,
    visibility = Visibility,
    sea_level_pressure = Sea.Level.Pressure
  )
```

Standardize airquality data
```{r}
airquality_clean <- airquality %>%
  transmute(
    year = Year,
    marathon = Marathon,
    aqi = Overall.AQI.Value,
    main_pollutant = Main.Pollutant,
    co = as.numeric(CO),
    ozone = as.numeric(Ozone),
    pm10 = suppressWarnings(as.numeric(PM10)),
    pm25 = as.numeric(PM2.5),
    no2 = as.numeric(NO2)
  )
```

Combine the marathon datasets
```{r}
# using bind_rows so we can row-wise combine and have data for each runner
marathons_all <- bind_rows(
  boston_clean,
  berlin_clean,
  nyc_clean,
  chicago_clean
)
str(marathons_all)
```

Select only years we need (1996 to 2025)
```{r}
marathons_all <- marathons_all %>%
  filter(year >= 1996 & year <= 2025)

str(marathons_all)
```

Chip-Time Cleaning Function (pulled from chatgbt): need chip_seconds to find the average finishing times
```{r}
clean_chip_time <- function(x) {
  
  # Convert numeric Excel-style times to character HH:MM:SS
  x_numeric <- suppressWarnings(as.numeric(x))
  is_fraction <- !is.na(x_numeric) & x_numeric < 1 & x_numeric > 0
  
  x[is_fraction] <- format(
    as.POSIXct("1970-01-01", tz = "UTC") + x_numeric[is_fraction] * 86400,
    "%H:%M:%S"
  )
  
  # Everything else treat as text and clean
  x <- as.character(x)
  x <- trimws(x)
  
  # Replace known invalid strings with NA
  invalid <- c("", "NA", "N/A", "—", "-", "DNF", "DNS", "DQ", "no time", "No Time", "NO TIME")
  x[x %in% invalid] <- NA
  
  # Pad missing zeros (H:MM:SS → HH:MM:SS, etc.)
  x <- gsub("^([0-9]):", "0\\1:", x)
  x <- gsub(":([0-9]):", ":0\\1:", x)
  x <- gsub(":([0-9])$", ":0\\1", x)
  
  return(x)
}

```

Clean chip_time
```{r}
marathons_all <- marathons_all %>%
  mutate(chip_time_clean = clean_chip_time(chip_time))
```

Convert the cleaned chip_time values to H:M:S and get chip_seconds
```{r}
marathons_all <- marathons_all %>%
  mutate(
    chip_seconds = suppressWarnings(period_to_seconds(hms(chip_time_clean)))
  )
```

```{r}
head(marathons_all)
```

Need to see what we want to do with these missing values and where they are coming from
```{r}
marathons_all %>% 
  summarize(missing_finish_times = sum(is.na(chip_seconds)))

marathons_all %>% 
  filter(is.na(chip_seconds))
```

Remove missing finish times. This is safe because we only use average finishing times in our model, so individual missing times don not matter. Also there are only 3 total. 
```{r}
marathons_all <- marathons_all %>%
  filter(!is.na(chip_seconds))
```

Labeling Gender as 'male', 'female', or 'unknown', nonbinary falls under female

```{r}
unique(marathons_all$gender)
```

```{r}
marathons_all <- marathons_all %>%
  mutate(
    gender = tolower(gender),
    gender = case_when(
      gender %in% c("male", "m") ~ "male",
      gender %in% c("female", "f", "w", "x", "nonbinary", "nb") ~ "female",
      TRUE ~ "unknown"
    )
  )

table(marathons_all$gender)
```

Removing unknowns since we have only 29 unknowns, and they will not help the model and most likely add noise:
```{r}
marathons_all <- marathons_all %>% 
  filter(gender != "unknown")

table(marathons_all$gender)
```


Creating time_ratio and using histogram to create subgroups 
```{r}
# Add winner_time for each marathon-year-gender
runners <- marathons_all %>%
  group_by(marathon, year, gender) %>%
  mutate(winner_time = min(chip_seconds, na.rm = TRUE)) %>%
  ungroup() %>%
  mutate(time_ratio = chip_seconds / winner_time)

# Create subgroups based on time_ratio
runners <- runners %>%
  mutate(
    subgroup = case_when(
      time_ratio <= 1.30 ~ "elite",
      time_ratio > 1.30 & time_ratio <= 1.55 ~ "competitive",
      time_ratio > 1.55 & time_ratio <= 1.80 ~ "average",
      time_ratio > 1.80 & time_ratio <= 2.10 ~ "recreational",
      time_ratio > 2.10 ~ "slow",
      TRUE ~ NA_character_
    ),
    subgroup = factor(subgroup, levels = c("elite", "competitive", "average", "recreational", "slow"))
  )

ggplot(runners, aes(x = time_ratio, fill = gender)) +
  geom_histogram(binwidth = 0.05, position = "dodge") +
  scale_fill_manual(values = c("female" = "deeppink", "male" = "steelblue")) +
  geom_vline(xintercept = c(1.3, 1.55, 1.80, 2.10), linetype = "dashed", color = "red") +
  labs(
    title = "Distribution of Runner Time Ratios to Winner by Gender",
    x = "Time Ratio (Runner / Winner)",
    y = "Count"
  ) +
  theme_minimal()
```

```{r}
runners %>%
  group_by(gender, subgroup) %>%
  summarise(count = n()) %>%
  arrange(gender, subgroup)
```

Compute average finishing time per subgroup
```{r}
avg_times <- runners %>%
  group_by(marathon, year, gender, subgroup) %>%
  summarize(
    n = n(),  # number of runners in each subgroup
    avg_chip_seconds = mean(chip_seconds, na.rm = TRUE),  
    .groups = "drop"
  )

avg_times
```

Left join weather_clean and airquailty_clean onto the cleaned marathon datasets
```{r}
final_data <- avg_times %>%
  left_join(weather_clean, by = c("year", "marathon")) %>%
  left_join(airquality_clean, by = c("year", "marathon"))

# move n (number of individuals representing each group) to the first column for neatness
final_data <- final_data %>% 
  select(n, everything())

final_data
str(final_data)
```

Export final data to csv
```{r}
#write_csv(final_data, "merged_marathon_data.csv")
```

